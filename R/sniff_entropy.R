#' Calculate Entropy Based on Keywords Over Time
#'
#' Computes the entropy of keyword distributions from scientific publications
#' over a specified time range. Entropy measures the diversity and uniformity
#' of keyword usage within research groups or the entire network.
#'
#' @param network A network object to analyze. For `scope = "groups"`, this should be
#'   the output of `sniff_groups()`. For `scope = "network"`, this should be a
#'   `tbl_graph` or `igraph` object from `sniff_network()`.
#' @param scope Character specifying the analysis scope: "groups" for multiple groups
#'   or "network" for the entire network (default: "groups").
#' @param start_year Starting year for entropy calculation. If NULL, uses the minimum
#'   publication year found in the network data.
#' @param end_year Ending year for entropy calculation. If NULL, uses the maximum
#'   publication year found in the network data.
#'
#' @return A list with three components:
#'   \item{data}{A tibble containing entropy values for each group and year}
#'   \item{plots}{A list of plotly objects visualizing entropy trends for each group}
#'   \item{years_range}{A vector with the start_year and end_year used in calculations}
#'
#' @details
#' The function calculates normalized entropy based on Shannon's information theory
#' (Shannon, 1948). Entropy quantifies the average level of uncertainty in keyword
#' distributions and measures the randomness or disorder within research groups.
#'
#' The normalized entropy is a scale-independent measure of uncertainty that can be
#' used to compare the uncertainty of different groups. It is calculated using the
#' formula:
#' \deqn{H = -\frac{\sum_{i=1}^{n} p_i \log_2 p_i}{n}}
#' where \eqn{p_i} is the probability of keyword \eqn{i} and \eqn{n} is the number
#' of unique keywords.
#'
#' Entropy values range from 0 to 1, where:
#' - 0 indicates minimal diversity (few dominant keywords, low uncertainty)
#' - 1 indicates maximal diversity (uniform keyword distribution, high uncertainty)
#'
#' @references
#' Shannon, C. E. (1948). A mathematical theory of communication. \emph{Bell System
#' Technical Journal}, 27(3), 379-423. doi: \doi{https://doi.org/10.1002/j.1538-7305.1948.tb01338.x}
#'
#' The concept of entropy measures the randomness or disorder in the group and provides
#' insights into the diversity of research topics and thematic concentration within
#' scientific communities.
#'
#' @importFrom tidygraph activate
#' @importFrom tibble as_tibble
#' @importFrom dplyr mutate filter select pull group_by summarise n
#' @importFrom tidyr separate_rows
#' @importFrom purrr safely map map_dfr map2
#' @importFrom stringr str_squish
#' @importFrom igraph V
#' @importFrom stats na.omit
#' @importFrom glue glue
#' @export
#'
#' @examples
#' \dontrun{
#' # Calculate entropy for groups from sniff_groups() output
#' groups_data <- sniff_groups(your_network_data)
#' entropy_results <- sniff_entropy(groups_data, scope = "groups")
#'
#' # Calculate entropy for entire network from sniff_network() output
#' network_data <- sniff_network(your_network_data)
#' entropy_results <- sniff_entropy(network_data, scope = "network")
#'
#' # Specify custom year range
#' entropy_results <- sniff_entropy(
#'   groups_data,
#'   scope = "groups",
#'   start_year = 2010,
#'   end_year = 2020
#' )
#'
#' # Access results
#' entropy_data <- entropy_results$data
#' entropy_plots <- entropy_results$plots
#' year_range <- entropy_results$years_range
#'
#' # Interpret results: higher entropy indicates greater keyword diversity
#' high_entropy_groups <- entropy_data %>%
#'   group_by(group) %>%
#'   summarise(mean_entropy = mean(index, na.rm = TRUE)) %>%
#'   arrange(desc(mean_entropy))
#' }
#'
#' @seealso
#' \code{\link{sniff_groups}}, \code{\link{sniff_network}}, \code{\link{indexes_plots}}
#'
#' @keywords entropy diversity keywords uncertainty shannon information-theory
sniff_entropy <- function(network, scope = "groups", start_year = NULL, end_year = NULL) {
  # Input validation
  if (is.null(network)) {
    stop("Network data not found in groups object", call. = FALSE)
  }

  required_scope <- c("network", "groups")
  if (!scope %in% required_scope) {
    stop(glue::glue("scope must be: {paste(required_scope, collapse = ' or ')}"), call. = FALSE)
  }

  if (scope == "groups") {
    # Input validation for groups scope
    list_dimensions <- c("network", "pubs_by_year", "aggregate")
    if (!all(list_dimensions %in% names(network))) {
      stop(glue::glue("network file must be generated by sniff_groups()"), call. = FALSE)
    }
    net_data <- network$network
  } else {
    # Input validation for network scope

    if (!inherits(network, c("tbl_graph", "igraph"))) {
      stop("Input (network) must be a network object (tbl_graph or igraph)", call. = FALSE)
    }

    network |>
      tidygraph::activate(nodes) |>
      dplyr::mutate(group = "full_network") ->
      net_data
  }

  # Determine start_year and end_year if not provided
  if (is.null(start_year) || is.null(end_year)) {
    publication_years <- tryCatch(
      {
        igraph::V(net_data)$PY
      },
      error = function(e) {
        stop("Error accessing publication years from network: ", e$message, call. = FALSE)
      }
    )

    publication_years <- publication_years[!is.na(publication_years)]

    if (length(publication_years) == 0) {
      stop("No publication years found in network data", call. = FALSE)
    }

    if (is.null(start_year)) {
      start_year <- min(publication_years, na.rm = TRUE)
      message("Using minimum publication year as start_year: ", start_year)
    }

    if (is.null(end_year)) {
      end_year <- max(publication_years, na.rm = TRUE)
      message("Using maximum publication year as end_year: ", end_year)
    }
  }

  if (start_year >= end_year) {
    stop("start_year must be less than end_year", call. = FALSE)
  }

  # Get unique groups
  group <- tryCatch(
    {
      net_data |>
        tidygraph::activate(nodes) |>
        tibble::as_tibble() |>
        dplyr::pull("group") |>
        stats::na.omit() |>
        unique() |>
        sort() ->
        unique_groups

      unique_groups
    },
    error = function(e) {
      stop("Error extracting groups from network: ", e$message, call. = FALSE)
    }
  )

  if (length(group) == 0) {
    stop("No valid groups found for analysis", call. = FALSE)
  }

  # Safe function for entropy calculation
  safe_entropy_calc <- purrr::safely(function(grp, year, net_data) {
    result_data <- net_data |>
      tidygraph::activate(nodes) |>
      tibble::as_tibble() |>
      dplyr::filter(.data$group == grp) |>
      dplyr::select("DE", "PY") |>
      tidyr::separate_rows("DE", sep = ";") |>
      dplyr::mutate(DE = stringr::str_squish(tolower(.data$DE))) |>
      dplyr::filter(!is.na(.data$DE) & .data$DE != "") |>
      dplyr::filter(.data$PY <= year)

    # Check if there's enough data to calculate entropy
    if (nrow(result_data) == 0) {
      return(data.frame(index = NA, year = year, group = grp))
    }

    result_data |>
      dplyr::group_by(.data$DE) |>
      dplyr::summarise(freq = dplyr::n(), .groups = "drop") |>
      dplyr::mutate(P = .data$freq / sum(.data$freq)) |>
      dplyr::summarise(
        index = (-sum(.data$P * log2(.data$P), na.rm = TRUE)) / dplyr::n(),
        .groups = "drop"
      ) |>
      dplyr::mutate(year = year, group = grp) ->
      result

    # Handle NaN values (when P = 0 or only one category)
    if (is.nan(result$index) || is.infinite(result$index)) {
      result$index <- 0
    }

    return(result)
  })

  entropy_list <- purrr::map(group, function(grp) {
    years_seq <- start_year:end_year

    results <- purrr::map_dfr(years_seq, function(year) {
      result <- safe_entropy_calc(grp, year, net_data)
      if (!is.null(result$error)) {
        warning(
          "Error calculating entropy for group ", grp, " year ", year,
          ": ", result$error$message
        )
        return(data.frame(index = NA, year = year, group = grp))
      }
      return(result$result)
    })

    return(results)
  })

  names(entropy_list) <- group

  # Combine all entropy data
  dplyr::bind_rows(entropy_list) |>
    dplyr::select("group", "year", "index") ->
    entropy_data

  # Create plots for each group
  plots_list <- purrr::map2(entropy_list, group, \(x, y) indexes_plots(x, group_name = y, start_year, end_year, method = "entropy"))

  result <- list(
    data = entropy_data,
    plots = plots_list,
    years_range = c(start_year = start_year, end_year = end_year)
  )

  return(result)
}
